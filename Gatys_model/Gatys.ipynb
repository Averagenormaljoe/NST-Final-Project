{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f9b2d72a",
      "metadata": {},
      "source": [
        "## 1 Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cb5f5ab",
      "metadata": {},
      "source": [
        "This is the notebook for the Gatys model from [the Gatys et al. paper](https://doi.org/10.1109/CVPR.2016.265). This serves as the main stylisation baseline of the NST project. This project will define a \n",
        "gradient descent process for an optimization loop."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b58ca0c",
      "metadata": {},
      "source": [
        "## 1.1 Checking the environment of the project"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eba8272d",
      "metadata": {},
      "source": [
        "Check the Python version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc1a28db",
      "metadata": {},
      "outputs": [],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8621659",
      "metadata": {},
      "source": [
        "Checking if the project is in Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "230bb803",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "KAGGLE_DIR_PATH = \"/kaggle/input/\"\n",
        "KAGGLE_SCRIPT_PATHS =  [\"/kaggle/input/gatys_model/gatys_model\", \"/kaggle/input/shared-utils/shared-utils\", \"/kaggle/input/video_utils/video_utils\"]\n",
        "on_kaggle : bool = True if any(\"kaggle\" in path for path in sys.path) else False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7e4c515",
      "metadata": {},
      "source": [
        "Checking if the project is in Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4750e8a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "import importlib\n",
        "def check_if_on_colab():\n",
        "    on_colab = 'google.colab' in str(get_ipython())\n",
        "    return on_colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "34b06ada",
      "metadata": {},
      "outputs": [],
      "source": [
        "on_colab = check_if_on_colab()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dec6dff5",
      "metadata": {},
      "source": [
        "Adding base paths for the project to allow the import to work the same way in colab and Kaggle as it would in a local environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de66109c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "def add_base_script_paths():\n",
        "  if on_colab:\n",
        "    sys.path.append('/content/drive/MyDrive')\n",
        "    nb_path = '/content/drive/MyDrive/Library'\n",
        "    os.makedirs(nb_path, exist_ok=True)\n",
        "    sys.path.insert(0,nb_path)\n",
        "    \n",
        "  elif on_kaggle:\n",
        "    kaggle_dir_path = KAGGLE_DIR_PATH\n",
        "    kaggle_script_paths = KAGGLE_SCRIPT_PATHS\n",
        "    sys.path.insert(1, kaggle_dir_path)\n",
        "    for x in  kaggle_script_paths:\n",
        "      if x not in sys.path:\n",
        "        sys.path.insert(1, x)\n",
        "  else:\n",
        "    sys.path.append('..')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cf130ec",
      "metadata": {},
      "outputs": [],
      "source": [
        "add_base_script_paths()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92e6f75d",
      "metadata": {},
      "source": [
        "Create a function to see if Google Drive is mounted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a44a580",
      "metadata": {},
      "outputs": [],
      "source": [
        "def is_drive_mounted():\n",
        "    drive_path = \"/content/drive\"\n",
        "    return os.path.exists(drive_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3c88b52",
      "metadata": {},
      "outputs": [],
      "source": [
        "drive_available = is_drive_mounted()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59f2a535",
      "metadata": {},
      "source": [
        "## 2 Image-based Style Transfer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd124732",
      "metadata": {},
      "source": [
        "Set the avalible cuda visible devices to 0, to prevent from using two GPUs at once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f644203",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "# ensures it can only access the first GPU\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01040499",
      "metadata": {},
      "source": [
        "Control the log output of the tqdm class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16f9234b",
      "metadata": {},
      "outputs": [],
      "source": [
        "TQDM_DISABLE=1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60065fd0",
      "metadata": {},
      "source": [
        "Import the tensorflow library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "903f5410",
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daf543a7",
      "metadata": {},
      "source": [
        "Prints the tensorflow version used by the project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50c931e5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.19.0\n"
          ]
        }
      ],
      "source": [
        "# prints the tensorflow version\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7cd3f80",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "04ed93a2",
      "metadata": {},
      "source": [
        "Download the shared util and helper functions library for usage in the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbe67b55",
      "metadata": {},
      "outputs": [],
      "source": [
        "def clone_repo(should_clone = False,token = \"\"):\n",
        "    if should_clone:\n",
        "        !git config --global url.\"https://{token}@github.com/\".insteadOf \"https://github.com/\"\n",
        "        !git clone --filter=blob:none --no-checkout https://github.com/Averagenormaljoe/Neural-Style-Transfer.git\n",
        "        !cd Neural-Style-Transfer\n",
        "        !git sparse-checkout init --cone\n",
        "        !git sparse-checkout set shared_utils\n",
        "        !git sparse-checkout set video_utils\n",
        "        !git sparse-checkout set helper_functions\n",
        "        !git sparse-checkout set gatys_functions\n",
        "        !git checkout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1844cfbb",
      "metadata": {},
      "outputs": [],
      "source": [
        "from shared_utils.colab_functions import download_libraries\n",
        "if on_colab:\n",
        "    nb_path = '/content/drive/MyDrive/Library'\n",
        "    download_libraries(nb_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a3ccc2d",
      "metadata": {},
      "source": [
        "List the GPUs use by the project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d0790df",
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (2059008399.py, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    from helper_functions.list\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "from helper_functions.list_devices import find_all_gpus"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bdd9afc",
      "metadata": {},
      "source": [
        "Get the GPU avaliable in the project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ef20bef",
      "metadata": {},
      "outputs": [],
      "source": [
        "find_all_gpus()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fe8eead",
      "metadata": {},
      "source": [
        "Get the available CPUs in the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce1b7bf0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available CPUs: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
          ]
        }
      ],
      "source": [
        "from helper_functions.list_devices import show_cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cbe4ccd",
      "metadata": {},
      "source": [
        "Show the number of CPUs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c075c145",
      "metadata": {},
      "outputs": [],
      "source": [
        "show_cpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "189e178d",
      "metadata": {},
      "source": [
        "Set the project to use the CPU and GPU of interest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "54da0bc4",
      "metadata": {},
      "outputs": [],
      "source": [
        "GPU_in_use: int = 0\n",
        "CPU_in_use: int = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "995a5a5f",
      "metadata": {},
      "outputs": [],
      "source": [
        "device_config = {\"gpu\" : GPU_in_use, \"cpu\" : CPU_in_use}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "00d9fb2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from helper_functions.device_helper import get_device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "375943ce",
      "metadata": {},
      "source": [
        "Define a function to see if there are any gpu available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1e93d2f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No GPU found\n"
          ]
        }
      ],
      "source": [
        "from helper_functions.list_devices import show_gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f22d598f",
      "metadata": {},
      "source": [
        "Next call the function to show the currently used GPUs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "220ed22b",
      "metadata": {},
      "outputs": [],
      "source": [
        "show_gpu(GPU_in_use)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d428ed7",
      "metadata": {},
      "source": [
        "Let define the paths for the demo images of the project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee0a671f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import keras\n",
        "base_image_path = \"../demo_images/san.png\"\n",
        "style_reference_image_paths = [\"../demo_images/starry_night.png\"]\n",
        "style_reference_path = style_reference_image_paths[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f5a2831",
      "metadata": {},
      "source": [
        "Define a function to get the size of the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "687186dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "from helper_functions.image_loader import get_size"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80a26e84",
      "metadata": {},
      "source": [
        "Retrieve the size of the image that the project plans to load."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4e7893d",
      "metadata": {},
      "outputs": [],
      "source": [
        "img_width, img_height = get_size(base_image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ea57f4b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from helper_functions.helper import  preprocess_image, deprocess_image\n",
        "from shared_utils.loss_functions import style_loss, content_loss, total_variation_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9acaa4fc",
      "metadata": {},
      "source": [
        "Define the single content loss for each layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c052e72",
      "metadata": {},
      "outputs": [],
      "source": [
        "total_variation_weight = 1e-6\n",
        "single_style_weight = 1e-6\n",
        "single_content_weight = 2.5e-8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "067bf350",
      "metadata": {},
      "outputs": [],
      "source": [
        "from shared_utils.gatys_network import get_content_layer_names,get_style_layer_names,get_style_weights, get_content_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66b85c32",
      "metadata": {},
      "source": [
        "The project will specify the loss network used for the gradient descent loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11e5bc38",
      "metadata": {},
      "outputs": [],
      "source": [
        "# the chosen loss network\n",
        "chosen_loss_network : str = \"vgg19\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1648ee9b",
      "metadata": {},
      "source": [
        "The next code snippet defines custom options for layers and weight, which is useful if we are using a loss network that is not 'vgg-19'.  \n",
        "If the 'use_custom' option is false it call the 'get_default_NST_layers' function as the return parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "295d2a35",
      "metadata": {},
      "outputs": [],
      "source": [
        "from gatys_functions.get_layers import get_layers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60453bc9",
      "metadata": {},
      "source": [
        "Run the function to get the default layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beba98d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "results = get_layers(False,chosen_loss_network)\n",
        "style_layer_names, content_layer_names, style_weights, content_weights = results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e1ccb92",
      "metadata": {},
      "outputs": [],
      "source": [
        "config_layers = {\n",
        "    \"style\" : style_layer_names,\n",
        "    \"content\" : content_layer_names\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46a76022",
      "metadata": {},
      "source": [
        "Next, the project will define a function to output the VGG-19 loss network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b887d6db",
      "metadata": {},
      "outputs": [],
      "source": [
        "from gatys_functions.get_model import get_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a731d7ec",
      "metadata": {},
      "source": [
        "Now, the project will retrieve the VGG-19 network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ec82231",
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_extractor = get_model(chosen_loss_network,img_width,img_height, config_layers=config_layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b359e93e",
      "metadata": {},
      "source": [
        "Let's define a function to compute the losses for the model. This function will iterate through each of the layers, calculating the features of the image and returning the content and style loss for the image.  \n",
        "This also calculates the total variation loss, along with additional losses (psnr, ssim, art, etc.) specified by the application. By default, it will only compute content, style, and total variation loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ffa83ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "from gatys_functions.compute_loss import compute_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7206d79d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5adcce0d",
      "metadata": {},
      "source": [
        "Sets whether to use the float 16 policy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6203e5dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "from shared_utils.policy import control_policy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79dd712e",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "74c139f1",
      "metadata": {},
      "source": [
        "Call the policy function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12789b2b",
      "metadata": {},
      "outputs": [],
      "source": [
        "control_policy(enable_mixed_precision=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a58d16a2",
      "metadata": {},
      "source": [
        "Create the compute loss and grads function. This will define a gradient tape, which gradients will be used to update the  \n",
        "stylized image (combination image) between each iteration. If multi style images are provided for the loss function, it will  \n",
        "compute them as a part of multi-neural style transfer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "945fb7e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from gatys_functions.compute_loss_and_grads import compute_loss_and_grads"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4870a894",
      "metadata": {},
      "source": [
        "Set the function for processing multi style images for multi neural style transfer."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d361dfb2",
      "metadata": {},
      "source": [
        "Create a noise function to supply initial noise for the content image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9be2e60",
      "metadata": {},
      "outputs": [],
      "source": [
        "from helper_functions.image_helper import add_noise_to_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c11dc97",
      "metadata": {},
      "outputs": [],
      "source": [
        "from helper_functions.helper import match_style_color_to_base"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b1ad8dc",
      "metadata": {},
      "source": [
        "Define a function to easily preprocess the base, style and combination image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35809758",
      "metadata": {},
      "outputs": [],
      "source": [
        "from gatys_functions.preprocess_NST_images import preprocess_NST_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb2cae2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92b40ca2",
      "metadata": {},
      "source": [
        "Define a function to call the 'compute_loss_and_grads' function to apply the gradients to the combination image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c1bac47",
      "metadata": {},
      "outputs": [],
      "source": [
        "from video_utils.mask import warp_previous_frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b2e4a32",
      "metadata": {},
      "outputs": [],
      "source": [
        "from video_utils.helper.get_flow_and_wrap import get_flow_and_wrap\n",
        "from video_utils.helper.reset_warp_frames import reset_warp_frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc96f1e6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from gatys_functions.apply_style_transfer_step import apply_style_transfer_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2ae0b1f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from helper_functions.bestImage import BestImage"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f18016b",
      "metadata": {},
      "source": [
        "Now, the project will define the training loop. This loop represent the gradient descent process, and will accept the path of a content and style images before\n",
        "generating the combination image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2796a70f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from helper_functions.log_funcs import create_log_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd410ab6",
      "metadata": {},
      "source": [
        "This will handle the config for the training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae8b75f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from helper_functions.ConfigManager import ConfigManager"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76f606d4",
      "metadata": {},
      "source": [
        "Next, let define the loop manager for handling the steps in the process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcbc9883",
      "metadata": {},
      "outputs": [],
      "source": [
        "from shared_utils.compute_custom_losses import CustomLosses"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65ef0528",
      "metadata": {},
      "source": [
        "Next, the project will define the training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0d61c44",
      "metadata": {},
      "outputs": [],
      "source": [
        "from gatys_functions.LoopManager import LoopManager"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e350d7ec",
      "metadata": {},
      "source": [
        "Define the folders for the content and style images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "636a95dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "base_dir = \"user_study_images/\"\n",
        "content_folder = f\"{base_dir}content\"\n",
        "style_folder = f\"{base_dir}style\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05fd9fb0",
      "metadata": {},
      "source": [
        "Define a function to collect the image files from the directory with the specified file extension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adbef0bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "from shared_utils.file_nav import get_image_files"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e656651",
      "metadata": {},
      "source": [
        "Next, use the function to retrieve the content and style files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d2e765a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "content_images = get_image_files(content_folder)\n",
        "style_images = get_image_files(style_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c26f9b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "content_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6575286",
      "metadata": {},
      "outputs": [],
      "source": [
        "style_images"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34dbcfb8",
      "metadata": {},
      "source": [
        "Define a function that allows the project to easily update the style model and content layers, along with weights."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a747e8ab",
      "metadata": {},
      "source": [
        "Setup the hyperparameter configuration for the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13de9396",
      "metadata": {},
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"optimizer\": \"adam\",\n",
        "    \"ln\": \"vgg19\",\n",
        "    \"lr\": 1.0,\n",
        "    \"size\": (img_width,img_height),\n",
        "    \"content_layer_names\": content_layer_names,\n",
        "    \"style_layer_names\": style_layer_names,\n",
        "    \"feature\" : feature_extractor,\n",
        "    \"c_weight\": single_content_weight,\n",
        "    \"s_weight\": single_style_weight,\n",
        "    \"tv_weight\": total_variation_weight,\n",
        "    \"video_mode\": False\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "362f2bbc",
      "metadata": {},
      "source": [
        "Setup the loop manager class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "864dbfe0",
      "metadata": {},
      "outputs": [],
      "source": [
        "loop_manager = LoopManager(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc607270",
      "metadata": {},
      "source": [
        "Next, define two function that will use the training loop but track the results of each image in the list and store into an array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7e9d400",
      "metadata": {},
      "outputs": [],
      "source": [
        "from shared_utils.file_nav import get_base_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4a9a625",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Layo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: ['keras_tensor']\n",
            "Received: inputs=Tensor(shape=(3, 400, 535, 3))\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "in user code:\n\n    File \"C:\\Users\\Layo\\AppData\\Local\\Temp\\ipykernel_19984\\189228123.py\", line 7, in compute_loss_and_grads  *\n        loss = compute_loss(\n    File \"C:\\Users\\Layo\\AppData\\Local\\Temp\\ipykernel_19984\\2033682352.py\", line 6, in compute_loss  *\n        layer_features = features[content_layer_name]\n\n    TypeError: unhashable type: 'list'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m generated_images, best_image, best_cost \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[31], line 22\u001b[0m, in \u001b[0;36mtraining_loop\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m start_time_wall \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/GPU:0\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# Place operations explicitly on GPU\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     loss, grads \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_loss_and_grads\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcombination_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle_reference_image\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mapply_gradients([(grads, combination_image)])\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\Layo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file9ail4i8z.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__compute_loss_and_grads\u001b[1;34m(combination_image, base_image, style_reference_image)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/GPU:0\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m---> 12\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombination_image\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_image\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstyle_reference_image\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     grads \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tape)\u001b[38;5;241m.\u001b[39mgradient, (ag__\u001b[38;5;241m.\u001b[39mld(loss), ag__\u001b[38;5;241m.\u001b[39mld(combination_image)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file7iqz5dzs.py:13\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__compute_loss\u001b[1;34m(combination_image, base_image, style_reference_image)\u001b[0m\n\u001b[0;32m     11\u001b[0m features \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(feature_extractor), (ag__\u001b[38;5;241m.\u001b[39mld(input_tensor),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mzeros, (), \u001b[38;5;28mdict\u001b[39m(shape\u001b[38;5;241m=\u001b[39m()), fscope)\n\u001b[1;32m---> 13\u001b[0m layer_features \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent_layer_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     14\u001b[0m base_image_features \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(layer_features)[\u001b[38;5;241m0\u001b[39m, :, :, :]\n\u001b[0;32m     15\u001b[0m combination_features \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(layer_features)[\u001b[38;5;241m2\u001b[39m, :, :, :]\n",
            "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Layo\\AppData\\Local\\Temp\\ipykernel_19984\\189228123.py\", line 7, in compute_loss_and_grads  *\n        loss = compute_loss(\n    File \"C:\\Users\\Layo\\AppData\\Local\\Temp\\ipykernel_19984\\2033682352.py\", line 6, in compute_loss  *\n        layer_features = features[content_layer_name]\n\n    TypeError: unhashable type: 'list'\n"
          ]
        }
      ],
      "source": [
        "# iterate through the content and style images\n",
        "def loop_through_images(content_images, style_images,loop_manager : LoopManager,config = {}):\n",
        "    image_set = []\n",
        "    best_image_set = []\n",
        "    image_data_logs = []\n",
        "    image_paths = []\n",
        "    for content_path in content_images:\n",
        "        content_name = get_base_name(content_path)\n",
        "        for style_path in style_images:\n",
        "            style_name = get_base_name(style_path)\n",
        "            results = loop_manager.training_loop(\n",
        "                content_path, style_path,\n",
        "                content_name, style_name, config=config\n",
        "            )\n",
        "            if results is None:\n",
        "                print(f\"Failed loop for ({content_name}) and ({style_name}). Next loop...\")\n",
        "                continue\n",
        "            generated_images, best_image,log_data = results\n",
        "            image_set.append(generated_images)\n",
        "            best_image_set.append(best_image)\n",
        "            image_data_logs.append(log_data)\n",
        "            image_paths.append((content_path, style_path))\n",
        "    return image_set, best_image_set, image_data_logs, image_paths"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a83b4940",
      "metadata": {},
      "source": [
        "Execute the function on the content and style directory paths in the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aabfaff1",
      "metadata": {},
      "outputs": [],
      "source": [
        "image_set, best_image_set, image_data_logs, image_paths = loop_through_images(content_images, style_images,loop_manager,config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aaa3d508",
      "metadata": {},
      "source": [
        "The next function collects the image information from the list in the loop to display the data in matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb6e5370",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_image_info(i):\n",
        "    generated_images = image_set[i]\n",
        "    best_image = best_image_set[i]\n",
        "    iterations = image_data_logs[i][\"iterations\"]\n",
        "    losses = image_data_logs[i][\"loss\"]\n",
        "    image_path = image_paths[i]\n",
        "    return generated_images, best_image, iterations, losses, image_path"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f7b66be",
      "metadata": {},
      "source": [
        "Get the image data using the function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62e79d8e",
      "metadata": {},
      "outputs": [],
      "source": [
        "generated_images,best_image, iterations, losses, image_path = get_image_info(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5382449",
      "metadata": {},
      "outputs": [],
      "source": [
        "from helper_functions.display_results import display_NST_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6a5772c",
      "metadata": {},
      "source": [
        "Displays the results as a matplotlib graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36376e4e",
      "metadata": {},
      "outputs": [],
      "source": [
        "generated_images,best_image, iterations, losses, image_path = get_image_info(0)\n",
        "display_NST_results(generated_images, best_image, iterations, losses, image_path, start_index = 0, config = config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb4c3b34",
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_NST_results(start_ranges = [0]):\n",
        "    length = len(image_set)\n",
        "    for i in range(length):\n",
        "        for start_i in start_ranges:\n",
        "                generated_images,best_image, iterations, losses, get_image_paths = get_image_info(i)\n",
        "                display_NST_results(generated_images, best_image, iterations, losses, get_image_paths, start_index = start_i)\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11c6ceca",
      "metadata": {},
      "outputs": [],
      "source": [
        "start_ranges = [0]\n",
        "save_NST_results(start_ranges)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "853777f9",
      "metadata": {},
      "source": [
        "Place the results into a table and convert them to a '.csv' table to store the hardware metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4274b4ad",
      "metadata": {},
      "outputs": [],
      "source": [
        "from helper_functions.table_saver import  save_and_show_all\n",
        "save_and_show_all(image_data_logs, image_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b91e439b",
      "metadata": {},
      "source": [
        "## 3 Video Style Transfer "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95ff286b",
      "metadata": {},
      "source": [
        "This section will define a set of functions to stylize a video using a sample url and images before storing the video into a dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73d91c60",
      "metadata": {},
      "outputs": [],
      "source": [
        "from video_utils.helper.loop_through_videos import loop_through_videos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14eb6892",
      "metadata": {},
      "source": [
        "Let define the style image paths and the video path to loop through."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57db4069",
      "metadata": {},
      "outputs": [],
      "source": [
        "style_paths = [\"user_study_images/style/starry_night.png\",\"user_study_images/style/picasso.jpg\", \"user_study_images/style/art16.jpg\", \"user_study_images/style/art12.jpg\", \"user_study_images/style/art7.jpg\"]\n",
        "video_content_path = \"demo_video/man_at_sea_sliced.mp4\"\n",
        "apply_video = loop_manager.training_loop\n",
        "total_logs = loop_through_videos(apply_video,style_paths, video_content_path,config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec7d9b8d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from video_utils.save_video_logs_table import save_video_logs_table"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb56aac8",
      "metadata": {},
      "source": [
        "End the notebook at this point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93aedc28",
      "metadata": {},
      "outputs": [],
      "source": [
        "save_video_logs_table(total_logs, \"videos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff1126aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "top_folder_name = \"Gatys_model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12942d5c",
      "metadata": {},
      "outputs": [],
      "source": [
        "video_save_path : str = f\"{top_folder_name}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e3ca5c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "def run_loop(tw = 1.0, save_path : str) -> list[dict]:\n",
        "    luminance_versions = [1,2,3,0]\n",
        "    style_paths = style_images\n",
        "    video_content_path = \"demo_video/man_at_sea_sliced.mp4\"\n",
        "    time_logs = []\n",
        "    for v in luminance_versions:\n",
        "        long_term = [True,False]\n",
        "        flow_conditions = [True]\n",
        "        mask_conditions = [True,False]\n",
        "        is_luminance = False if v == 0 else True\n",
        "        for term in long_term:\n",
        "            for is_flow in flow_conditions:\n",
        "                for is_mask in mask_conditions:\n",
        "                    config = {\n",
        "                                \n",
        "                            \"is_mask\" : is_mask,\n",
        "                            \"is_multi_pass\" : is_mask,\n",
        "                            \"is_flow\" : is_flow,\n",
        "                            \"verbose\" : 1,\n",
        "                            \"frames_limit\" : 10000,\n",
        "                            \"long_term\" : term,\n",
        "                            \"is_luminance\" : is_luminance,\n",
        "                            \"temporal_weight\" : tw,\n",
        "                            \"luminance_version\" : v,\n",
        "                    \n",
        "                    }\n",
        "                    log = config.copy()\n",
        "                    start_time = time.time()\n",
        "                    cpu_start_time =  time.process_time()\n",
        "                    v_cond = \"off\" if not is_luminance else str(v)\n",
        "                    mask_cond = \"off\" if not is_mask else str(is_mask)\n",
        "                    flow_cond = \"off\" if not is_mask else str(is_flow)\n",
        "                    video_save_path = f\"{top_folder_name}_johnson_multi_pass_{mask_cond}_luminance_{v_cond}_long_term_{term}_tw_{tw}_flow_{flow_cond}_mask_{mask_cond}\"\n",
        "                    total_logs = loop_through_videos(apply_video,style_paths, video_content_path,f\"{video_save_path}\",config=config)\n",
        "                    save_video_logs_table(total_logs,save_path,prefix= f\"{video_save_path}_man_logs\")\n",
        "                    end_time = (time.time() - start_time)\n",
        "                    cpu_end_time = (time.process_time() - cpu_start_time)\n",
        "                    log.update({\"time\": end_time, \"cpu_time\" : cpu_end_time, \"path\": video_save_path})\n",
        "                    time_logs.append(log)\n",
        "    return time_logs\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "203fc636",
      "metadata": {},
      "outputs": [],
      "source": [
        "from shared_utils.helper import create_dir\n",
        "\n",
        "\n",
        "save_path = \"video_data\"\n",
        "create_dir(save_path=save_path)\n",
        "time_logs = run_loop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "792152c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_time = pd.DataFrame(time_logs)\n",
        "df_time_csv_path = os.path.join(save_path, f\"{top_folder_name}_video_time.csv\")\n",
        "df_time.to_csv(df_time_csv_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79161e07",
      "metadata": {},
      "source": [
        "End of the notebook."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
